{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load('config.yml')\n",
    "\n",
    "# Replace with your Confluent Cloud Kafka cluster details\n",
    "bootstrap_servers = [config['confluent']['bootstrap_servers']]  # e.g. 'pkc-xxxxxx.us-east-1.aws.confluent.cloud:9092'\n",
    "\n",
    "\n",
    "# Configure Spark to read from Kafka\n",
    "kafka_options = {\n",
    "    \"kafka.bootstrap.servers\": bootstrap_servers ,\n",
    "    \"subscribe\": \"weather-readings\",\n",
    "    \"startingOffsets\": \"earliest\",\n",
    "    \"kafka.security.protocol\": \"SASL_SSL\",  # Confluent Cloud\n",
    "    \"kafka.sasl.mechanism\": \"PLAIN\"         # Confluent Cloud\n",
    "}\n",
    "\n",
    "# Read streaming data from Kafka\n",
    "weather_stream = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .options(**kafka_options) \\\n",
    "    .load()\n",
    "\n",
    "# Parse JSON data and convert timestamp\n",
    "from pyspark.sql.functions import from_json, col, window, to_timestamp, expr\n",
    "from pyspark.sql.types import StructType,StructField,StringType,DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"sensor_id\", StringType()),\n",
    "    StructField(\"temperature\", DoubleType()),\n",
    "    StructField(\"humidity\", DoubleType()),\n",
    "    StructField(\"wind_speed\", DoubleType()),\n",
    "    StructField(\"timestamp\", StringType())\n",
    "])\n",
    "\n",
    "# Parse the JSON and convert timestamp string to timestamp type\n",
    "parsed_stream = weather_stream \\\n",
    "    .select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "\n",
    "# Now create windows on the timestamp column with clean column names\n",
    "windowed_stats = parsed_stream \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(\"timestamp\", \"5 minutes\").alias(\"time_window\"),\n",
    "        \"sensor_id\"\n",
    "    ) \\\n",
    "    .agg(\n",
    "        expr(\"avg(temperature)\").alias(\"avg_temperature\"),\n",
    "        expr(\"avg(humidity)\").alias(\"avg_humidity\"),\n",
    "        expr(\"avg(wind_speed)\").alias(\"avg_wind_speed\")\n",
    "    ) \\\n",
    "    .select(\n",
    "        \"sensor_id\",\n",
    "        col(\"time_window.start\").alias(\"window_start\"),\n",
    "        col(\"time_window.end\").alias(\"window_end\"),\n",
    "        \"avg_temperature\",\n",
    "        \"avg_humidity\",\n",
    "        \"avg_wind_speed\"\n",
    "    )\n",
    "\n",
    "# Write to Delta Lake\n",
    "query = windowed_stats \\\n",
    "    .writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint/weather_stats\") \\\n",
    "    .table(\"weather_stats\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
